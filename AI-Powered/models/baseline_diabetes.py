"""
Baseline Diabetes Prediction Model
Ù†Ù…ÙˆØ°Ø¬ Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø³ÙƒØ±ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Random Forest
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    classification_report, 
    confusion_matrix, 
    roc_auc_score,
    roc_curve,
    precision_recall_curve,
    average_precision_score
)
import joblib
import os
import json
from datetime import datetime

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ preprocessing pipeline
from preprocessing import (
    load_and_prepare_data,
    create_preprocessing_pipeline,
    save_pipeline,
    load_pipeline
)


class DiabetesPredictor:
    """
    Ù†Ù…ÙˆØ°Ø¬ Ù…ØªÙƒØ§Ù…Ù„ Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø³ÙƒØ±ÙŠ
    """
    
    def __init__(self, model_type='random_forest', use_scaling=False):
        """
        Parameters:
        -----------
        model_type : str
            Ù†ÙˆØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ('random_forest', 'xgboost', 'lightgbm')
        use_scaling : bool
            Ø§Ø³ØªØ®Ø¯Ø§Ù… StandardScaler
        """
        self.model_type = model_type
        self.use_scaling = use_scaling
        self.preprocessing_pipeline = None
        self.model = None
        self.feature_names = None
        self.training_history = {}
        
    def _create_model(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­Ø¯Ø¯"""
        if self.model_type == 'random_forest':
            return RandomForestClassifier(
                n_estimators=200,
                max_depth=15,
                min_samples_split=10,
                min_samples_leaf=4,
                class_weight='balanced',
                random_state=42,
                n_jobs=-1,
                verbose=1
            )
        elif self.model_type == 'xgboost':
            try:
                import xgboost as xgb
                return xgb.XGBClassifier(
                    n_estimators=200,
                    max_depth=6,
                    learning_rate=0.1,
                    subsample=0.8,
                    colsample_bytree=0.8,
                    scale_pos_weight=5,  # Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ imbalance
                    random_state=42,
                    n_jobs=-1
                )
            except ImportError:
                print("âš ï¸ XGBoost ØºÙŠØ± Ù…Ø«Ø¨ØªØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Random Forest")
                return self._create_model_rf()
        elif self.model_type == 'lightgbm':
            try:
                import lightgbm as lgb
                return lgb.LGBMClassifier(
                    n_estimators=200,
                    max_depth=6,
                    learning_rate=0.1,
                    subsample=0.8,
                    colsample_bytree=0.8,
                    class_weight='balanced',
                    random_state=42,
                    n_jobs=-1
                )
            except ImportError:
                print("âš ï¸ LightGBM ØºÙŠØ± Ù…Ø«Ø¨ØªØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Random Forest")
                return self._create_model_rf()
        else:
            raise ValueError(f"Ù†ÙˆØ¹ Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ: {self.model_type}")
    
    def train(self, X_train, y_train, X_val=None, y_val=None):
        """
        ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        
        Parameters:
        -----------
        X_train : DataFrame
            Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        y_train : Series
            Ø§Ù„Ø£Ù‡Ø¯Ø§Ù
        X_val : DataFrame (optional)
            Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚
        y_val : Series (optional)
            Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ­Ù‚Ù‚
        """
        print("\n" + "="*80)
        print("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨...")
        print("="*80)
        
        # Ø¥Ù†Ø´Ø§Ø¡ preprocessing pipeline
        print("\n1ï¸âƒ£ Ø¥Ù†Ø´Ø§Ø¡ Preprocessing Pipeline...")
        self.preprocessing_pipeline = create_preprocessing_pipeline(
            scale_features=self.use_scaling
        )
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        print("2ï¸âƒ£ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
        X_train_processed = self.preprocessing_pipeline.fit_transform(X_train)
        
        # Ø­ÙØ¸ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ÙŠØ²Ø§Øª
        if hasattr(X_train_processed, 'columns'):
            self.feature_names = X_train_processed.columns.tolist()
        else:
            # ÙÙŠ Ø­Ø§Ù„Ø© numpy array
            self.feature_names = [f"feature_{i}" for i in range(X_train_processed.shape[1])]
        
        print(f"   âœ… Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {X_train_processed.shape[1]}")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        print(f"\n3ï¸âƒ£ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ {self.model_type}...")
        self.model = self._create_model()
        
        # Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        print("4ï¸âƒ£ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")
        start_time = datetime.now()
        
        self.model.fit(X_train_processed, y_train)
        
        training_time = (datetime.now() - start_time).total_seconds()
        print(f"   âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙÙŠ {training_time:.2f} Ø«Ø§Ù†ÙŠØ©")
        
        # Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        self.training_history = {
            'model_type': self.model_type,
            'training_samples': len(X_train),
            'features_count': X_train_processed.shape[1],
            'training_time_seconds': training_time,
            'timestamp': datetime.now().isoformat()
        }
        
        # ØªÙ‚ÙŠÙŠÙ… Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        print("\n5ï¸âƒ£ ØªÙ‚ÙŠÙŠÙ… Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨...")
        train_score = self.model.score(X_train_processed, y_train)
        print(f"   Training Accuracy: {train_score:.4f}")
        
        # ØªÙ‚ÙŠÙŠÙ… Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ù† ÙˆØ¬Ø¯Øª
        if X_val is not None and y_val is not None:
            print("\n6ï¸âƒ£ ØªÙ‚ÙŠÙŠÙ… Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚...")
            X_val_processed = self.preprocessing_pipeline.transform(X_val)
            val_score = self.model.score(X_val_processed, y_val)
            print(f"   Validation Accuracy: {val_score:.4f}")
            
            self.training_history['validation_accuracy'] = val_score
        
        print("\nâœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ù†Ø¬Ø§Ø­!")
        
    def evaluate(self, X_test, y_test, verbose=True):
        """
        ØªÙ‚ÙŠÙŠÙ… Ø´Ø§Ù…Ù„ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
        
        Returns:
        --------
        dict : Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
        """
        if self.model is None:
            raise ValueError("ÙŠØ¬Ø¨ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙˆÙ„Ø§Ù‹!")
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        X_test_processed = self.preprocessing_pipeline.transform(X_test)
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤
        y_pred = self.model.predict(X_test_processed)
        y_proba = self.model.predict_proba(X_test_processed)[:, 1]
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
        results = {
            'accuracy': self.model.score(X_test_processed, y_test),
            'roc_auc': roc_auc_score(y_test, y_proba),
            'average_precision': average_precision_score(y_test, y_proba),
            'confusion_matrix': confusion_matrix(y_test, y_pred).tolist(),
            'classification_report': classification_report(y_test, y_pred, output_dict=True)
        }
        
        if verbose:
            print("\n" + "="*80)
            print("ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…")
            print("="*80)
            print(f"\nğŸ¯ Accuracy: {results['accuracy']:.4f}")
            print(f"ğŸ“ˆ ROC-AUC: {results['roc_auc']:.4f}")
            print(f"ğŸ“Š Average Precision: {results['average_precision']:.4f}")
            
            print("\nğŸ“‹ Classification Report:")
            print(classification_report(y_test, y_pred))
            
            print("\nğŸ”¢ Confusion Matrix:")
            cm = results['confusion_matrix']
            print(f"   TN: {cm[0][0]:6d}  |  FP: {cm[0][1]:6d}")
            print(f"   FN: {cm[1][0]:6d}  |  TP: {cm[1][1]:6d}")
        
        return results
    
    def predict(self, X, return_proba=False):
        """
        Ø§Ù„ØªÙ†Ø¨Ø¤ Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©
        
        Parameters:
        -----------
        X : DataFrame or dict
            Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªÙ†Ø¨Ø¤
        return_proba : bool
            Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª
            
        Returns:
        --------
        predictions or (predictions, probabilities)
        """
        if self.model is None:
            raise ValueError("ÙŠØ¬Ø¨ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙˆÙ„Ø§Ù‹!")
        
        # ØªØ­ÙˆÙŠÙ„ dict Ø¥Ù„Ù‰ DataFrame Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
        if isinstance(X, dict):
            X = pd.DataFrame([X])
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        X_processed = self.preprocessing_pipeline.transform(X)
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤
        predictions = self.model.predict(X_processed)
        
        if return_proba:
            probabilities = self.model.predict_proba(X_processed)
            return predictions, probabilities
        
        return predictions
    
    def get_feature_importance(self, top_n=20):
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª
        
        Returns:
        --------
        DataFrame : Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙˆØ£Ù‡Ù…ÙŠØªÙ‡Ø§
        """
        if self.model is None:
            raise ValueError("ÙŠØ¬Ø¨ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙˆÙ„Ø§Ù‹!")
        
        if hasattr(self.model, 'feature_importances_'):
            importances = self.model.feature_importances_
            
            # Ø¥Ù†Ø´Ø§Ø¡ DataFrame
            feature_imp = pd.DataFrame({
                'feature': self.feature_names,
                'importance': importances
            }).sort_values('importance', ascending=False)
            
            return feature_imp.head(top_n)
        else:
            print("âš ï¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ø§ ÙŠØ¯Ø¹Ù… feature_importances_")
            return None
    
    def save(self, model_path='models/saved/diabetes_model.pkl'):
        """Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù€ pipeline"""
        if self.model is None:
            raise ValueError("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø­ÙØ¸!")
        
        os.makedirs(os.path.dirname(model_path), exist_ok=True)
        
        # Ø­ÙØ¸ ÙƒÙ„ Ø´ÙŠØ¡ ÙÙŠ dict ÙˆØ§Ø­Ø¯
        model_data = {
            'model': self.model,
            'preprocessing_pipeline': self.preprocessing_pipeline,
            'feature_names': self.feature_names,
            'model_type': self.model_type,
            'training_history': self.training_history
        }
        
        joblib.dump(model_data, model_path)
        print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ: {model_path}")
        
        # Ø­ÙØ¸ metadata ÙƒÙ€ JSON
        metadata_path = model_path.replace('.pkl', '_metadata.json')
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(self.training_history, f, indent=2, ensure_ascii=False)
        print(f"âœ… ØªÙ… Ø­ÙØ¸ Metadata ÙÙŠ: {metadata_path}")
    
    @classmethod
    def load(cls, model_path='models/saved/diabetes_model.pkl'):
        """ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­ÙÙˆØ¸"""
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {model_path}")
        
        model_data = joblib.load(model_path)
        
        # Ø¥Ù†Ø´Ø§Ø¡ instance Ø¬Ø¯ÙŠØ¯
        predictor = cls(model_type=model_data['model_type'])
        predictor.model = model_data['model']
        predictor.preprocessing_pipeline = model_data['preprocessing_pipeline']
        predictor.feature_names = model_data['feature_names']
        predictor.training_history = model_data['training_history']
        
        print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù†: {model_path}")
        return predictor


# Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
if __name__ == "__main__":
    print("="*80)
    print("ğŸ¥ Diabetes Prediction - Baseline Model")
    print("="*80)
    
    # Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
    data_path = "../DataSet/diabetes_binary_health_indicators_BRFSS2015.csv"
    
    if not os.path.exists(data_path):
        print(f"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {data_path}")
        exit(1)
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    print("\nğŸ“‚ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    X_train, X_test, y_train, y_test = load_and_prepare_data(
        data_path,
        test_size=0.2,
        random_state=42
    )
    
    print(f"âœ… Training: {X_train.shape}, Testing: {X_test.shape}")
    print(f"âœ… ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù‡Ø¯Ù - Training: {y_train.value_counts().to_dict()}")
    
    # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    predictor = DiabetesPredictor(model_type='random_forest', use_scaling=False)
    predictor.train(X_train, y_train)
    
    # Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
    results = predictor.evaluate(X_test, y_test)
    
    # Ø¹Ø±Ø¶ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª
    print("\n" + "="*80)
    print("ğŸ” Ø£Ù‡Ù… Ø§Ù„Ù…ÙŠØ²Ø§Øª")
    print("="*80)
    feature_imp = predictor.get_feature_importance(top_n=15)
    if feature_imp is not None:
        print(feature_imp.to_string(index=False))
    
    # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    print("\n" + "="*80)
    print("ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")
    print("="*80)
    predictor.save()
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙ†Ø¨Ø¤ Ù„Ø­Ø§Ù„Ø© ÙˆØ§Ø­Ø¯Ø©
    print("\n" + "="*80)
    print("ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙ†Ø¨Ø¤")
    print("="*80)
    
    sample_patient = X_test.iloc[0].to_dict()
    print(f"Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±ÙŠØ¶: {sample_patient}")
    
    pred, proba = predictor.predict(sample_patient, return_proba=True)
    print(f"\nâœ… Ø§Ù„ØªÙ†Ø¨Ø¤: {'Ø³ÙƒØ±ÙŠ' if pred[0] == 1 else 'Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø³ÙƒØ±ÙŠ'}")
    print(f"âœ… Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„: {proba[0][1]:.2%}")
    
    print("\n" + "="*80)
    print("âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø¨Ù†Ø¬Ø§Ø­!")
    print("="*80)
